{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk3vPkbs9kSE5xtgHXTl6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuelhurni/ML-Cellsegmentation-HSLU-FS24/blob/feature_Sam/Code/Sartorius_segmentation_kaggle_Sam_v001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Sartorius - Cell Instance Segmentation\n",
        "##Detect single neuronal cells in microscopy images\n",
        "\n",
        "Project HSLU Master IT Digitalization & Sustainability\n",
        "Module: Machine Learning and Data Science\n",
        "* Samuel Hurni\n",
        "* Pradanendr Sudev  \n",
        "* Chakravarti Devanandini\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l6zoX0SeIhBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.1 General information and references\n",
        "\n",
        "Used Third party Libraries:\n",
        "* Pytorch\n",
        "* TQDM\n",
        "* Pandas\n",
        "* Numpy\n",
        "* gdown\n",
        "* Matplotlib\n",
        "\n",
        "Used Thid party Imports:\n",
        "* Auxiliary functions metric: \"https://www.kaggle.com/code/theoviel/competition-metric-map-iou\n",
        "* Auxiliary functions for encoding and decoding the mask: \"https://www.kaggle.com/code/enzou3/sartorius-mask-r-cnn\"\n",
        "\n",
        "\n",
        "\n",
        "References to Turtorials / Code documantation:\n",
        "* Pytorch documentation: https://pytorch.org/docs/stable/index.html\n",
        "* Pytorch Turtorial: https://www.learnpytorch.io/00_pytorch_fundamentals/\n",
        "* Kaggel dataset for ideas: https://www.kaggle.com/code/enzou3/sartorius-mask-r-cnn\n",
        "  * build own method based on `find_best_thresholds()`\n",
        "\n",
        "\n",
        "\n",
        "  **Important:**\n",
        "  **Please check the Hyperparameters for this File because this allows you for example to run the project with limited images or load pretrained models**"
      ],
      "metadata": {
        "id": "q5rAGNxLJqnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2 About the project\n",
        "\n",
        "Link to the project as follow: https://www.kaggle.com/competitions/sartorius-cell-instance-segmentation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Main objectives:\n",
        "\n",
        "This Kaggle competition is about creating a computer program to identify and outline individual nerve cells in microscope images. These nerve cells are important for studying brain diseases like Alzheimer's and brain tumors, which are major health problems worldwide. Typically, scientists look at these cells using a microscope, but finding each cell in the images can be tough and takes a lot of time. Doing this accurately could help find new treatments for these diseases.\n",
        "\n",
        "The challenge is that current methods aren't very good at recognizing these nerve cells, especially a kind called neuroblastoma cells, which look very different from other cells and are hard to identify with existing tools.\n",
        "\n",
        "Sartorius, a company that supports science and medicine research, is sponsoring this competition. They want participants to develop a method that can automatically and precisely identify different types of nerve cells in images. This would be a big step forward in neurological research, making it easier for scientists to understand how diseases affect nerve cells and possibly leading to the discovery of new medications.\n",
        "\n",
        "\n",
        "\n",
        "Dataset:\n",
        "\n",
        "The Dataset containa at arround xx images for training and xx images for testing. the goal would be to train a model whoch is able to segment neuronal cells.\n",
        "\n",
        "\n",
        "The ground truth data to the images for training consist several meta data which includes also the masks for training the segmentation problem. These are specified field of ecah datapoint:\n",
        "\n",
        "\n",
        "* _id - unique identifier for object_\n",
        "\n",
        "* _annotation - run length encoded pixels for the identified neuronal cell_\n",
        "\n",
        "* _width - source image width_\n",
        "\n",
        "* _height - source image height_\n",
        "\n",
        "* _cell_type - the cell line_\n",
        "\n",
        "* _plate_time - time plate was created_\n",
        "\n",
        "* _sample_date - date sample was created_\n",
        "\n",
        "* _sample_id - sample identifier_\n",
        "\n",
        "* _elapsed_timedelta - time since first image taken of sample_\n",
        "\n"
      ],
      "metadata": {
        "id": "hCJr31AcKlyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a7vC51jVI7wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Preparations: Loading Dataset and install or import Packages"
      ],
      "metadata": {
        "id": "FUGWIF-fI8Vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Install adn import third party packages / functions\n",
        "\n",
        "In this chapter we install the third party packages which maybe are not installed in the prebuild google collab or on your local system\n",
        "\n",
        "* Tqdm --> progress bar\n",
        "* gdown --> Import google drive package\n"
      ],
      "metadata": {
        "id": "JWwrrWRkPXSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gdown:\n",
        "try:\n",
        "    import gdown\n",
        "except ImportError:\n",
        "    !pip install gdown\n",
        "\n",
        "# Install tqdm:\n",
        "try:\n",
        "    import tqdm\n",
        "except ImportError:\n",
        "    !pip install tqdm"
      ],
      "metadata": {
        "id": "FM3PVEqnPdwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General Import which are used in this file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import os.path\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import requests\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import gdown\n",
        "from sklearn.metrics import fbeta_score"
      ],
      "metadata": {
        "id": "9024sz-hPm4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Define custom functions for this Project:\n",
        "\n",
        "In this chapter we are defining custom functions which we are using throughout this project:\n",
        "\n",
        "* `show_train_time` function to show the time how long the coputation of the model takes\n",
        "* `folder_content` function to display what is inside a folder\n",
        "* `check_drop_image_existence` function to drop from the label dataset images which are not in the file system\n",
        "* `accuracy_fn` function for multi-label calssification problems\n",
        "* `plot_loss_values` for plotting the loss and accuracy to detect under or overfitting\n",
        "* `model_rating` gives back the rating of the model with accuracy and score for a given dataloader dataset\n",
        "* `make_pred` make predictions with a model based on test data\n",
        "* `combine_models_predictions_2` combines the results of two models with the size of 4 and 13 labels to a result of 17 labels\n",
        "* `make_pred_combined` make predctions for the combined approach  with two models, one for the weather labels and another for the other labelsm\n",
        "\n"
      ],
      "metadata": {
        "id": "woSCLCKBPwKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the timing function:\n",
        "from timeit import default_timer as timer\n",
        "def show_train_time(start:float,\n",
        "                     end:float,\n",
        "                     device: torch.device = None):\n",
        "  \"\"\"Show differnences between start and end time for calculation the performance of a pytorch model\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "PLL3UP7MP0LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def folder_content(directory_path):\n",
        "  \"\"\"\n",
        "  Iterating thorugh all folders in the path and display the content.\n",
        "  Args:\n",
        "    directory_path --> Path to start iteration\n",
        "\n",
        "  Returns:\n",
        "    Show information about:\n",
        "      subdiretories in dir_path\n",
        "      number of files in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(directory_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "e1H0AP2eP52F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_drop_image_existence(label_data: pd.DataFrame, images_dir : string):\n",
        "  \"\"\"\n",
        "  Method which cleans the label dataframe by checking the existence of images\n",
        "  \"\"\"\n",
        "  data_frame = label_data\n",
        "  index_drop = []\n",
        "  #print(f\"Check Images in Folder {images_dir}\")\n",
        "  for index, row in tqdm(data_frame.iterrows(), desc=\"Checking if File Exists.....\"):\n",
        "    path_to_check = os.path.join(images_dir, row['image_name'])\n",
        "    file_exists = os.path.isfile(path_to_check)\n",
        "    if file_exists == False:\n",
        "      # File does not exist, drop row from dataset\n",
        "      #print(f\"File: {row['image_name']} in Label file does not exist as image and will be deleted from the label file\")\n",
        "      index_drop.append(index)\n",
        "\n",
        "  #Drop all rows in index_drop\n",
        "  for index in tqdm(index_drop, desc=\"Deleting rows in label dataset.....\"):\n",
        "    data_frame.drop(index, inplace=True)\n",
        "  return data_frame"
      ],
      "metadata": {
        "id": "LIb-468qP_hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Checking for GPU and device agnostic code (Cuda(Nvidia / Apple Silicon)\n",
        "\n",
        "In this chapter we are checking if Hardware from Nvidia (Cuda framework) pr Apple Silicon (M1-M3) is available and switching the device"
      ],
      "metadata": {
        "id": "Q6-lqvEeQJOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup device agnostic code\n",
        "import torch\n",
        "device=\"cpu\"\n",
        "if torch.backends.mps.is_available():\n",
        "  print(\"Metal available with Apple Silicon GPU\")\n",
        "  device = \"mps\"\n",
        "elif torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "  print(\"Cuda available with Nvidia GPU\")"
      ],
      "metadata": {
        "id": "0f-zw1nnQNZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Define Hyperparameter for Project:\n",
        "Her we have the hyperparameters for all three models:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GyIPTYl_QXG_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZodKdmiQZdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Downloading the dataset to Google Colab\n",
        "\n",
        "In this chapter we are downloading the dataset from a public Google Drive link to this colab instance. This is necessary to decrease the request time per image to the dataset:"
      ],
      "metadata": {
        "id": "B_llEUiIQjVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import zipfile\n",
        "import gdown\n",
        "\n",
        "# Setup paths and folders names and urls\n",
        "data_path = Path(\"dataset\")\n",
        "download_path = Path(\"kaggledownload\")\n",
        "\n",
        "dataset_url = 'https://drive.google.com/uc?id=1syZoLGGeFiFErCFL_iI1VO_4k2jLEaPv&confirm=t'\n",
        "\n",
        "\n",
        "# If the image folder doesn't exist, download it\n",
        "if data_path.is_dir():\n",
        "    print(f\"{data_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {data_path} directory, creating one...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    download_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Downloading dataset...\")\n",
        "gdown.download(dataset_url, str(download_path / \"sartorius-cell-instance-segmentation.zip\"), quiet=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dRgnuDd3QkU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unzip data\n",
        "with zipfile.ZipFile(str(download_path / \"sartorius-cell-instance-segmentation.zip\"), \"r\") as zip_ref:\n",
        "    print(\"Unzipping train dataset data...\")\n",
        "    zip_ref.extractall(data_path)"
      ],
      "metadata": {
        "id": "W1VPnCiJQycG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Dataset preparation\n",
        "\n",
        "In this chapter we are preparing our dataset, that we are able to load it later on into a Pytorch Dataloader:\n",
        "\n",
        "* Load dataset from path\n",
        "* Add missing ending \".jpg\" that column name matches to filename\n",
        "* Splitting up label classes from label column\n",
        "* Add vectrized column `[0,1,0,0,1,....]`"
      ],
      "metadata": {
        "id": "TNXyajeuQ5lT"
      }
    }
  ]
}